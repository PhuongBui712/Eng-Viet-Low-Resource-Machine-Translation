{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En-Vi Translator with low resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q install torch torchvision torchaudio\n",
    "# !pip install -q transformers sentencepiece datasets accelerate evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, cfg, split='train', prefix=''):\n",
    "        self.cfg = cfg\n",
    "\n",
    "        src_texts, tgt_texts = self.read_data(split, prefix)\n",
    "\n",
    "        self.src_input_ids = self.text_to_sequence(src_texts)\n",
    "        self.labels = self.text_to_sequence(tgt_texts)\n",
    "\n",
    "    def read_data(self, split, prefix):\n",
    "        dataset = load_dataset('mt_eng_vietnamese', \n",
    "                               'iwslt2015-en-vi', \n",
    "                               split=split,\n",
    "                               cache_dir=self.cfg.cache_dir)\n",
    "\n",
    "        src_texts = [prefix + sample['translation'][self.cfg.src_lang] for sample in dataset]\n",
    "        tgt_texts = [sample['translation'][self.cfg.tgt_lang] for sample in dataset]\n",
    "\n",
    "        return src_texts, tgt_texts\n",
    "    \n",
    "    def text_to_sequence(self, text):\n",
    "        inputs = self.cfg.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.cfg.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return inputs.input_ids\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'input_ids': self.src_input_ids[index],\n",
    "            'labels': self.labels[index]\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.shape(self.src_input_ids)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class NMTConfig(BaseConfig):\n",
    "    # Data\n",
    "    src_lang = 'en'\n",
    "    tgt_lang = 'vi'\n",
    "    max_length = 75\n",
    "    add_special_token = True\n",
    "    augmented_data_size = 0.0001\n",
    "\n",
    "    # Model\n",
    "    model_name = \"VietAI/envit5-translation\"\n",
    "    cache_dir = './.cache/'\n",
    "\n",
    "    # Training\n",
    "    device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    if device == 'mps':\n",
    "        use_mps_device=True\n",
    "        \n",
    "    learning_rate = 1e-5\n",
    "    train_batch_size = 16\n",
    "    eval_batch_size = 16\n",
    "    num_train_epochs = 2\n",
    "    save_total_limit = 1\n",
    "    ckpt_dir = f'./checkpoints'\n",
    "    eval_steps = 1000\n",
    "\n",
    "    # interfere\n",
    "    beam_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = NMTConfig()\n",
    "finetuned = True\n",
    "\n",
    "try:\n",
    "    # Load model locally if exist\n",
    "    print('Try load model locally!')\n",
    "    model_dir = './models/finetuned-EnViT5'\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(model_dir, local_files_only=True)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_dir, local_files_only=True)\n",
    "    print('Loading local model successfully!')\n",
    "\n",
    "except:\n",
    "    print('Loading local model failed!\\nDownloading from Huggingface!')\n",
    "    cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, cache_dir=cfg.cache_dir)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(cfg.model_name, cache_dir=cfg.cache_dir)\n",
    "\n",
    "    finetuned = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('sacrebleu', cache_dir=cfg.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = cfg.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, cfg.tokenizer.pad_token_id)\n",
    "    decoded_labels = cfg.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != cfg.tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune on En-Vi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    output_dir=cfg.ckpt_dir,\n",
    "    per_device_train_batch_size=cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=cfg.eval_batch_size,\n",
    "    use_mps_device=cfg.use_mps_device,\n",
    "    save_total_limit=cfg.save_total_limit,\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    num_train_epochs=cfg.num_train_epochs,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=cfg.tokenizer,\n",
    "    model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not finetuned:\n",
    "    train_dataset = NMTDataset(cfg, 'train')\n",
    "    valid_dataset = NMTDataset(cfg, 'validation')\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        tokenizer=cfg.tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    model_dir = './models/finetuned-EnViT5'\n",
    "    trainer.save_model(output_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic data by back-translating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmented_NMTDataset(NMTDataset):\n",
    "    def __init__(self, cfg, augmented_src=[], augmented_tgt=[], split='train', prefix=''):\n",
    "        super().__init__(cfg, split, prefix)\n",
    "\n",
    "        augmented_src_sequence = self.text_to_sequence(augmented_src)\n",
    "        augmented_tgt_sequence = self.text_to_sequence(augmented_tgt)\n",
    "\n",
    "        self.src_input_ids = torch.cat((self.src_input_ids, augmented_src_sequence), dim=0)\n",
    "        self.labels = torch.cat((self.labels, augmented_tgt_sequence), dim=0)\n",
    "\n",
    "    def read_data(self, split, prefix):\n",
    "        return super().read_data(split, prefix)\n",
    "\n",
    "    def text_to_sequence(self, text):\n",
    "        return super().text_to_sequence(text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.src_input_ids[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return super().__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text,\n",
    "              tokenizer: PreTrainedTokenizer,\n",
    "              model: PreTrainedModel,\n",
    "              device=NMTConfig.device,\n",
    "              max_length=NMTConfig.max_length,\n",
    "              beam_size=NMTConfig.beam_size):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    device = torch.device(device)\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    outputs = model.generate(input_ids,\n",
    "                             attention_mask=attention_mask,\n",
    "                             max_length=max_length,\n",
    "                             early_stopping=True,\n",
    "                             num_beams=beam_size,\n",
    "                             length_penalty=2.0)\n",
    "\n",
    "    output_strs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    del input_ids\n",
    "    del attention_mask\n",
    "\n",
    "    return output_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_tgt_texts = load_data('./data/PhoMT/tokenization/train/train.vi')\n",
    "train_augmented_tgt_texts = train_augmented_tgt_texts[:int(cfg.augmented_data_size * len(train_augmented_tgt_texts))]\n",
    "\n",
    "eval_augmented_tgt_texts = load_data('./data/PhoMT/tokenization/dev/dev.vi')\n",
    "eval_augmented_tgt_texts = eval_augmented_tgt_texts[:int(cfg.augmented_data_size * len(eval_augmented_tgt_texts))]\n",
    "\n",
    "train_augmented_src_texts = []\n",
    "eval_augmented_src_texts = []\n",
    "\n",
    "batch_size = 32\n",
    "for s, tgt, src in zip(('train', 'validation'),\n",
    "                        (train_augmented_tgt_texts, eval_augmented_tgt_texts),\n",
    "                        (train_augmented_src_texts, eval_augmented_src_texts)):\n",
    "    print(f'Back translation {s} set')\n",
    "    for i in tqdm(range(len(tgt) // batch_size + 1)):\n",
    "        batch_data = tgt[i * batch_size: min((i + 1) * batch_size, len(tgt))]\n",
    "        output_strs = inference(batch_data, cfg.tokenizer, model)\n",
    "        output_strs = [output.strip('en: ') for output in output_strs]\n",
    "        src += output_strs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re - Train with new final data (original data + synthetic data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented_dataset = Augmented_NMTDataset(cfg,\n",
    "                                            augmented_src=train_augmented_src_texts,\n",
    "                                            augmented_tgt=train_augmented_tgt_texts,\n",
    "                                            split='train')\n",
    "eval_augmented_dataset = Augmented_NMTDataset(cfg,\n",
    "                                              augmented_src=eval_augmented_src_texts,\n",
    "                                              augmented_tgt=eval_augmented_tgt_texts,\n",
    "                                              split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=cfg.tokenizer,\n",
    "    train_dataset=train_augmented_dataset,\n",
    "    eval_dataset=eval_augmented_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/augmented-EnViT5'\n",
    "trainer.save_model(output_dir=model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
