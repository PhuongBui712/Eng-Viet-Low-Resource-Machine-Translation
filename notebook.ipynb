{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En-Vi Translator with low resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q install torch torchvision torchaudio\n",
    "# !pip install -q transformers sentencepiece datasets accelerate evaluate sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btp712/Code/EngViet Translator/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    def __init__(self, cfg, split='train', prefix=''):\n",
    "        self.cfg = cfg\n",
    "\n",
    "        src_texts, tgt_texts = self.read_data(split, prefix)\n",
    "\n",
    "        self.src_input_ids = self.text_to_sequence(src_texts)\n",
    "        self.labels = self.text_to_sequence(tgt_texts)\n",
    "\n",
    "    def read_data(self, split, prefix):\n",
    "        dataset = load_dataset('mt_eng_vietnamese', \n",
    "                               'iwslt2015-en-vi', \n",
    "                               split=split,\n",
    "                               cache_dir=self.cfg.cache_dir)\n",
    "\n",
    "        src_texts = [prefix + sample['translation'][self.cfg.src_lang] for sample in dataset]\n",
    "        tgt_texts = [sample['translation'][self.cfg.tgt_lang] for sample in dataset]\n",
    "\n",
    "        return src_texts, tgt_texts\n",
    "    \n",
    "    def text_to_sequence(self, text):\n",
    "        inputs = self.cfg.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.cfg.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return inputs.input_ids\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'input_ids': self.src_input_ids[index],\n",
    "            'labels': self.labels[index]\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.shape(self.src_input_ids)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "\n",
    "class NMTConfig(BaseConfig):\n",
    "    # Data\n",
    "    src_lang = 'en'\n",
    "    tgt_lang = 'vi'\n",
    "    max_length = 75\n",
    "    add_special_token = True\n",
    "\n",
    "    # Model\n",
    "    model_name = \"Helsinki-NLP/opus-mt-en-vi\"\n",
    "    cache_dir = './.cache/'\n",
    "\n",
    "    # Training\n",
    "    device = 'cuda' if torch.cuda.is_available() else ('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "    if device == 'mps':\n",
    "        use_mps_device=True\n",
    "        \n",
    "    learning_rate = 1e-5\n",
    "    train_batch_size = 16\n",
    "    eval_batch_size = 16\n",
    "    num_train_epochs = 2\n",
    "    save_total_limit = 1\n",
    "    ckpt_dir = f'./checkpoints'\n",
    "    eval_steps = 1000\n",
    "\n",
    "    # interfere\n",
    "    beam_search = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btp712/Code/EngViet Translator/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/btp712/Code/EngViet Translator/.venv/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "cfg = NMTConfig()\n",
    "cfg.tokenizer = AutoTokenizer.from_pretrained(cfg.model_name, cache_dir=cfg.cache_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(cfg.model_name, cache_dir=cfg.cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('sacrebleu', cache_dir=cfg.cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = cfg.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, cfg.tokenizer.pad_token_id)\n",
    "    decoded_labels = cfg.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != cfg.tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.8M/17.8M [00:01<00:00, 13.6MB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181k/181k [00:00<00:00, 223kB/s]\n",
      "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 181k/181k [00:00<00:00, 223kB/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133318/133318 [00:00<00:00, 1959745.77 examples/s]\n",
      "Generating validation split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1269/1269 [00:00<00:00, 529135.28 examples/s]\n",
      "Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1269/1269 [00:00<00:00, 841646.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "prefix = \"translate English to Vietnamese: \"\n",
    "\n",
    "train_dataset = NMTDataset(cfg, 'train', prefix=prefix)\n",
    "valid_dataset = NMTDataset(cfg, 'validation', prefix=prefix)\n",
    "test_dataset = NMTDataset(cfg, 'test', prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btp712/Code/EngViet Translator/.venv/lib/python3.12/site-packages/transformers/training_args.py:2046: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    output_dir=cfg.ckpt_dir,\n",
    "    per_device_train_batch_size=cfg.train_batch_size,\n",
    "    per_device_eval_batch_size=cfg.eval_batch_size,\n",
    "    use_mps_device=cfg.use_mps_device,\n",
    "    save_total_limit=cfg.save_total_limit,\n",
    "    learning_rate=cfg.learning_rate,\n",
    "    num_train_epochs=cfg.num_train_epochs,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=cfg.tokenizer,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=cfg.tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 60/83330 [00:45<16:32:11,  1.40it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/'\n",
    "trainer.save_model(output_dir=model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
